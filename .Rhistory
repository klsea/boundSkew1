age_ha <- ggplot(d1, aes(Age, ha)) + geom_point() + geom_smooth(method=lm) +
ggtitle('High Arousal')
multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
age_plots
age_plots <- multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
age_plots
multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(sjPlot)
source('../06_graph_affect.R')
affect
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
source('../06_graph_affect.R')
affect
summary(affectaov)
ttable %>%
kable() %>%
kable_styling(bootstrap_options = "striped")
ptable %>%
kable() %>%
kable_styling(bootstrap_options = "striped")
agecorr[,1:2] %>%
kable() %>%
kable_styling(bootstrap_options = "striped") %>%
row_spec(c(3,5:7), bold = T, background = 'yellow')
multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
agecorr[,1:2] %>%
kable() %>%
kable_styling("striped", full_width = F)) %>%
agecorr[,1:2] %>%
kable() %>%
kable_styling("striped", full_width = F) %>%
row_spec(c(3,5:7), bold = T, background = 'yellow')
# load required packages
library(here)
library(ggplot2)
library(tidyr)
# load source functions
source(here('scr', 'isolate_skew.R'))
source(here('scr', 'isolate_measure.R'))
source(here('scr', 'SummarySE.R'))
source(here('scr', 'pairedttable.R'))
source(here('scr', 'corrTableCI.R'))
source(here('scr', 'multiplot.R'))
# load data
dt <- read.csv(here("data", "bound_skew1_data.csv"))
dict <- read.csv(here("data", "bound_skew1_data_dictionary.csv"))
# isolate AVI data
Sys.setlocale('LC_ALL','C')
qs <- as.character(dict$Question)
first <- grep("Enthusiastic", qs)
last <- grep("Lonely", qs)
#last <- grep("Serene", qs)
d0 <- isolate_skew(dt,c(1,2), first:last)
# add labels to AVI data
d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Lonely", dict)
#d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Serene", dict)
d1 <- score_avi(d0)
# Graph means
d2 <- cbind(colMeans(d1), apply(d1, 2, sd), apply(d1, 2, sd)/sqrt(nrow(d1)))
d2 <- d2[3:nrow(d2),]
colnames(d2) <- c('Mean', 'SD', 'SE')
View(d2)
names <- rownames(d2); rownames(d2) <- NULL
gsub('ha', 'high arousal', names)
# 11.11.19 KLS
# load required packages
library(here)
library(ggplot2)
library(tidyr)
# load source functions
source(here('scr', 'isolate_skew.R'))
source(here('scr', 'isolate_measure.R'))
source(here('scr', 'SummarySE.R'))
source(here('scr', 'pairedttable.R'))
source(here('scr', 'corrTableCI.R'))
source(here('scr', 'multiplot.R'))
# set hard-coded variables
# load data
dt <- read.csv(here("data", "bound_skew1_data.csv"))
dict <- read.csv(here("data", "bound_skew1_data_dictionary.csv"))
# isolate AVI data
Sys.setlocale('LC_ALL','C')
qs <- as.character(dict$Question)
first <- grep("Enthusiastic", qs)
last <- grep("Lonely", qs)
#last <- grep("Serene", qs)
d0 <- isolate_skew(dt,c(1,2), first:last)
# add labels to AVI data
d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Lonely", dict)
#d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Serene", dict)
d1 <- score_avi(d0)
# Graph means
d2 <- cbind(colMeans(d1), apply(d1, 2, sd), apply(d1, 2, sd)/sqrt(nrow(d1)))
d2 <- d2[3:nrow(d2),]
colnames(d2) <- c('Mean', 'SD', 'SE')
names <- rownames(d2);
names
gsub('ha', 'high arousal', names)
gsub('la', 'low arousal', names)
gsub('p', ' - positive', names)
gsub('n', ' - negative', names)
names <- gsub('ha', 'high arousal', names)
names <- gsub('la', 'low arousal', names)
names <- gsub('p', ' - positive', names)
names <- gsub('n', ' - negative', names)
names
d2 <- cbind(names, d2)
d2 <- data.frame(d2)
d2$Mean <- as.numeric(as.character(d2$Mean))
d2$SD <- as.numeric(as.character(d2$SD))
d2$SE <- as.numeric(as.character(d2$SE))
d2$names <- names
#d2$names <- c( 'high arousal - positive', 'low arousal - positive', 'low arousal',
#              'low arousal - negative','high arousal -negative', 'high arousal')
d2$names <- factor(d2$names, levels =c('low arousal', 'low arousal - negative', 'low arousal - positive',
'high arousal','high arousal -negative', 'high arousal - positive'))
affect <- ggplot(d2, aes(names, Mean, fill = names)) + geom_bar(stat='identity') + annotate("text", x=1, y=0, label="Never") +
annotate("text", x=1, y=5, label="All the time") +
geom_errorbar(aes(ymin = Mean-SE, ymax = Mean + SE), width = .2, position=position_dodge(.9)) +
theme_minimal() + theme(legend.position = 'none', axis.text.x  = element_text(angle=90, vjust=0.5, size = 10)) + xlab("Affect") + ylab('Average Rating') +
expand_limits(y=c(1,5)) + geom_vline(aes(xintercept=3.5))
affect
# ANOVA
d3 <- gather(d1, condition, rating, hap:ha)
affectaov <- aov(rating ~ condition + Error(ID), d3)
summary(affectaov)
ttable <- pariedttable(d3,colnames(d1)[3:8], 1)
ptable <- pariedttable(d3,colnames(d1)[3:8], 2)
# Examine correlations with age
agecorr <- corrTableCI(d1[2:8])
#graphs
age_lap <- ggplot(d1, aes(Age, lap)) + geom_point() + geom_smooth(method=lm) +
ggtitle('Low Arousal - Positive')
age_lan <- ggplot(d1, aes(Age, lan)) + geom_point() + geom_smooth(method=lm) +
ggtitle('Low Arousal - Negative')
age_han <- ggplot(d1, aes(Age, han)) + geom_point() + geom_smooth(method=lm) +
ggtitle('High Arousal - Negative')
age_ha <- ggplot(d1, aes(Age, ha)) + geom_point() + geom_smooth(method=lm) +
ggtitle('High Arousal')
multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
View(d3)
View(d2)
write.csv(d2, here::here('oupput', 'affect1.csv'))
write.csv(d2, here::here('output', 'affect1.csv'))
source('~/github/boundSkew1/06_graph_affect.R', echo=TRUE)
source('~/github/boundSkew1/06_graph_affect.R', echo=TRUE)
source('~/github/boundSkew1/06_graph_affect.R', echo=TRUE)
write.csv(d2, here::here('output', 'affect1.csv'), row.names = FALSE)
affect <- ggplot(d2, aes(names, Mean, fill = names)) + geom_bar(stat='identity') + annotate("text", x=1, y=0, label="Never") +
annotate("text", x=1, y=5, label="All the time") +
geom_errorbar(aes(ymin = Mean-SE, ymax = Mean + SE), width = .2, position=position_dodge(.9)) +
theme_minimal() + theme(legend.position = 'none', axis.text.x  = element_text(angle=90, vjust=0.5, size = 10)) + xlab("Affect") + ylab('Average Rating') +
expand_limits(y=c(1,5)) + geom_vline(aes(xintercept=3.5))
# ANOVA
d3 <- gather(d1, condition, rating, hap:ha)
affectaov <- aov(rating ~ condition + Error(ID), d3)
summary(affectaov)
ttable <- pariedttable(d3,colnames(d1)[3:8], 1)
ptable <- pariedttable(d3,colnames(d1)[3:8], 2)
# Examine correlations with age
agecorr <- corrTableCI(d1[2:8])
#graphs
age_lap <- ggplot(d1, aes(Age, lap)) + geom_point() + geom_smooth(method=lm) +
ggtitle('Low Arousal - Positive')
age_lan <- ggplot(d1, aes(Age, lan)) + geom_point() + geom_smooth(method=lm) +
ggtitle('Low Arousal - Negative')
age_han <- ggplot(d1, aes(Age, han)) + geom_point() + geom_smooth(method=lm) +
ggtitle('High Arousal - Negative')
age_ha <- ggplot(d1, aes(Age, ha)) + geom_point() + geom_smooth(method=lm) +
ggtitle('High Arousal')
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
#multiplot(age_lap, age_lan, age_ha, age_han, cols = 2)
source('~/github/boundSkew1/06_graph_affect.R', echo=TRUE)
# load required packages
library(here)
library(ggplot2)
library(tidyr)
# load source functions
source(here('scr', 'isolate_skew.R'))
source(here('scr', 'isolate_measure.R'))
source(here('scr', 'SummarySE.R'))
source(here('scr', 'pairedttable.R'))
source(here('scr', 'corrTableCI.R'))
source(here('scr', 'multiplot.R'))
# load data
dt <- read.csv(here("data", "bound_skew1_data.csv"))
dict <- read.csv(here("data", "bound_skew1_data_dictionary.csv"))
# isolate AVI data
Sys.setlocale('LC_ALL','C')
qs <- as.character(dict$Question)
first <- grep("Enthusiastic", qs)
last <- grep("Lonely", qs)
#last <- grep("Serene", qs)
d0 <- isolate_skew(dt,c(1,2), first:last)
# add labels to AVI data
d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Lonely", dict)
#d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Serene", dict)
d1 <- score_avi(d0)
# Graph means
d2 <- cbind(colMeans(d1), apply(d1, 2, sd), apply(d1, 2, sd)/sqrt(nrow(d1)))
d2 <- d2[3:nrow(d2),]
colnames(d2) <- c('Mean', 'SD', 'SE')
names <- rownames(d2); rownames(d2) <- NULL
names <- gsub('ha', 'high arousal', names)
names
names <- gsub('p', ' - positive', names)
names <- gsub('n', ' - negative', names)
names
source('~/github/boundSkew1/06_graph_affect.R', echo=TRUE)
View(affect)
View(d2)
source('~/github/boundSkew1/06_graph_affect.R', echo=TRUE)
View(score_avi)
# load required packages
library(here)
library(Hmisc)
# load source functions
source(here('scr', 'isolate_skew.R'))
source(here('scr', 'isolate_measure.R'))
source(here('scr', 'clean_skew.R'))
source(here('scr', 'count_skew.R'))
source(here('scr', 'corrTableCI.R'))
# load data
dt <- read.csv(here("data", "bound_skew1_data.csv"))
dict <- read.csv(here("data", "bound_skew1_data_dictionary.csv"))
# separate skew
d0 <- isolate_skew(dt,c(1,2),10:69)
d1 <- clean_skew2(d0)
#recode response to acceptance
d1$accept <- d1$response - 1
# add skew count variable
d2 <-count_skew(d1)
rm(d0, d1)
# separate strategy
d0 <- isolate_skew(dt,c(1,2),70:75)
colnames(d0) <- c('ID', 'Age', 'gut', 'math', 'win.money', 'lose.money', 'win.likely', 'lose.likely')
# merge skew and strategy data frames
d3 <- merge(d2,d0, by = 'ID')
d3 <- d3[c(1,5,2:4,6:11)]
d3$skew_count <- as.integer(as.character(d3$skew_count))
rm(d0,d2)
# isolate AVI data
Sys.setlocale('LC_ALL','C')
qs <- as.character(dict$Question)
first <- grep("Enthusiastic", qs); last <- grep("Lonely", qs) # use if full measure: last <- grep("Serene", qs)
d0 <- isolate_skew(dt,c(1,2), first:last)
# add labels to AVI data
d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Lonely", dict) # use if full measure: d0 <- add_correct_avi_labels(d0, "Enthusiastic", "Serene", dict)
d1 <- score_avi(d0)
# merge affect to skew+strategy data frame
d4 <- merge(d3, d1, by = c('ID', 'Age'))
rm(d1,d3)
# isolate graph literacy
first <- grep("bar charts", qs); last <- grep("newspapers", qs)
d0 <- isolate_skew(dt,c(1,2), first:last)
# graph literacy score
d1 <- score_graph_lit(d0)
rm(d0)
# isolate numeracy
first <- grep("six-sided", qs); last <- grep("10,000 doctors", qs)
d2 <- isolate_skew(dt,c(1,2), first:last)
# score numeracy
ans_key <- create_num_answer_key()
d3 <- as.data.frame(score_num(d2, ans_key))
rm(ans_key, d2)
# merge cognitive to skew+strategy+affect data frame
d5 <- merge(d4, d1, by = c('ID', 'Age')); d6 <- merge(d5, d3, by = c('ID', 'Age'))
rm(d4, d1,d5,d3)
# identify begining and end of
d1 <- isolate_skew(dt, 1, grep('Q173', colnames(dt)):grep('Q27', colnames(dt)))
# investment & fraud
d2 <- data.frame(d1$ID, (d1$Q173 - 2)*-1, d1$Q177, d1[11:14])
colnames(d2) <- c('ID', 'lost_invest', 'why_lost', 'detect_fraud', 'likely_fraud', 'high_pressure', 'avoid_fraud')
# merge real world with skew+strategy+affect+cog
d7 <- merge(d6, d2, by = 'ID')
rm(d1,d2,d6)
View(d7)
# correlations
end <- ncol(d7); #grep('why_lost', colnames(d7))
s1_corr <- rcorr(as.matrix(d7[c(2, 5:20, 22:end)]))
View(s1_corr)
s1_corr
s1_corrCI <- corrTableCI(d7[c(2, 5:20, 22:end)])
saveRDS(s1_corr, here('output', 's1_corr.RDS'))
saveRDS(s1_corrCI, here('output', 's1_corrCI.RDS'))
source('~/github/boundSkew1/09_individual_differences.R', echo=TRUE)
View(s1_corr)
s1_corr$r
# load required packages
library(here)
library(ggplot2)
# load source functions
source(here('scr', 'isolate_skew.R'))
source(here('scr', 'isolate_measure.R'))
source(here('scr', 'SummarySE.R'))
# load data
dt <- read.csv(here("data", "bound_skew1_data.csv"))
dict <- read.csv(here("data", "bound_skew1_data_dictionary.csv"))
# isolate graph literacy
Sys.setlocale('LC_ALL','C')
qs <- as.character(dict$Question)
first <- grep("bar charts", qs)
last <- grep("newspapers", qs)
d0 <- isolate_skew(dt,c(1,2), first:last)
# graph literacy score
d1 <- score_graph_lit(d0)
# visualize graph literacy
sgl1 <- ggplot(d1, (aes(x=graph_lit))) + geom_histogram(binwidth = 0.5) +
geom_vline(aes(xintercept=mean(graph_lit, na.rm=T)), color="red", linetype="dashed", size=1)
sgl2 <- ggplot(d1, aes(Age, graph_lit)) + geom_point() + geom_smooth(method=lm)
# isolate numeracy
first <- grep("six-sided", qs)
last <- grep("10,000 doctors", qs)
d2 <- isolate_skew(dt,c(1,2), first:last)
View(d2)
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(Hmisc)
source('../07_graph_cognitive.R')
View(d3)
View(d1)
View(d1)
# make table
d4 <- merge(d1, d3, by = c("ID", "Age"))
View(d4)
write.csv(d4, here('output', 'cog1.csv', row.names = FALSE))
write.csv(d4, here('output', 'cog1.csv'), row.names = FALSE))
write.csv(d4, here('output', 'cog1.csv'), row.names = FALSE)
View(dict)
View(num2)
source('~/github/boundSkew1/03_model_skew.R', echo=TRUE)
# load required packages
library(here)
library(lme4)
library(gdata)
# load source functions
source(here('scr', 'isolate_skew.R'))
source(here('scr', 'clean_skew.R'))
source(here('scr', 'SummarySE.R'))
# load data
dt <- read.csv(here("data", "bound_skew1_data.csv"))
# separate skew
d0 <- isolate_skew(dt,c(1,2),10:69)
d1 <- clean_skew(d0)
# recode response to acceptance
d1$accept <- d1$response - 1
# reorder deg_skew factor
d1$deg_skew <- factor(d1$deg_skew, levels = c('Symmetric', 'Weak', 'Moderate', 'Strong'))
# reorder valence factor
d1$valence <- factor(d1$valence, levels = c('neutral', 'gain', 'loss'))
# make magnitude a factor
d1$magnitude <- factor(d1$magnitude, levels = c('0', '0.5', '5'))
# scale and center age
d1$Age <- scale(d1$Age)
# make interaction term
d1$magval <- interaction(d1$valence, d1$magnitude)
d1$magval <- drop.levels(d1$magval)
d1$magval <- factor(d1$magval, levels = c('neutral.0', 'loss.5', 'loss.0.5', 'gain.0.5', 'gain.5'))
# baseline - only degree of skew
b1 <- glmer(accept ~ deg_skew + (1 + Age | ID), data = d1, family = binomial(link = logit), nAGQ = 1,
control=glmerControl(optimizer='bobyqa'))
summary(b1, correlation = FALSE)
# boundary fit - remove age from random effects
b1.1 <- glmer(accept ~ deg_skew + (1 | ID), data = d1, family = binomial(link = logit), nAGQ = 1,
control=glmerControl(optimizer='bobyqa'))
summary(b1.1, correlation = FALSE)
saveRDS(b1.1, here('output', 'baseline.RDS'))
# model 1 - add valence
m1 <- glmer(accept ~ deg_skew * valence + (1 | ID), data = d1, family = binomial(link = logit), nAGQ = 1,
control=glmerControl(optimizer='bobyqa'))
summary(m1, correlation = FALSE)
saveRDS(m1, here('output', 'm1.RDS'))
# compare model 1 and model 2
anova(b1.1,m1)
View(d0)
View(d1)
View(d1)
library(tidyr)
View(d1)
View(d1)
View(d1)
View(d1)
##follow-up t-tests
d2 <- spread(d1[c(1,2,6,9)], deg_skew, accept)
d1[c(1,2,6,9)]
##follow-up t-tests
d2 <- spread(d1[c(1,6,9)], deg_skew, accept)
View(d1)
View(summarySE)
View(d1)
##follow-up t-tests
summarySE(d1, accept, groupvars = c('ID', 'deg_skew'))
##follow-up t-tests
summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew'))
##follow-up t-tests
d2 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew'))
View(d2)
d3 <- spread(d2, 'deg_skew', 'accept')
View(d3)
View(d2)
d3 <- spread(d2[,c(1,2,4)], 'deg_skew', 'accept')
View(d3)
t.test(d3$Symmetric, d3$Moderate, paired = TRUE)
b1t2 <- t.test(d3$Symmetric, d3$Moderate, paired = TRUE)
View(b1t2)
b1t2 <- t.test(d3$Symmetric, d3$Strong, paired = TRUE)
b1t2
b1t1 <- t.test(d3$Symmetric, d3$Weak, paired = TRUE)
b1t1
rm(d2,d3)
View(d1)
## follow-up t-tests
d4 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew', 'valence'))
View(d4)
View(d4)
cross(d4$deg_skew, d4$valence)
interaction(d4$deg_skew, d4$valence)
d4$skew_valence <- interaction(d4$deg_skew, d4$valence)
View(d4)
d5 <- spread(d4[,c(1,2,4)], 'skew_valence')
View(d4)
d5 <- spread(d4[,c(1,4,9)], 'skew_valence')
head(d4[,c(1,4,9)])
View(d4)
d5 <- spread(d4[,c(1,5,9)], 'skew_valence')
d5 <- spread(d4[,c(1,9,)], 'skew_valence')
d5 <- spread(d4[,c(1,9,)], 'skew_valence', 'accept')
d5 <- spread(d4[,c(1,9,5)], 'skew_valence', 'accept')
View(d5)
View(d5)
m1t1 <- t.test(d5$Symmetric.loss, d5$weak.loss, paired = TRUE)
View(d5)
m1t1 <- t.test(d5$Symmetric.loss, d5$Weak.loss, paired = TRUE)
View(m1t1)
m1t1
m1t2 <- t.test(d5$Symmetric.loss, d5$Moderate.loss, paired = TRUE)
m1t3 <- t.test(d5$Symmetric.loss, d5$Strong.loss, paired = TRUE)
m1t2
m1t3
d6 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew', 'magnitude'))
d6$skew_mag <- interaction(d6$deg_skew, d6$magnitude)
d7 <- spread(d6[,c(1,9,5)], 'skew_mag', 'accept')
View(d7)
## follow-up t-tests
d6 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew', 'magnitude'))
d6$skew_mag <- interaction(d6$deg_skew, d6$magnitude)
d7 <- spread(d6[,c(1,9,5)], 'skew_mag', 'accept')
m1t1 <- t.test(d7$Symmetric.5, d7$Weak.5, paired = TRUE)
m1t2 <- t.test(d7$Symmetric.5, d7$Moderate.5, paired = TRUE)
m1t3 <- t.test(d7$Symmetric.5, d7$Strong.5, paired = TRUE)
m2t1 <- t.test(d7$Symmetric.5, d7$Weak.5, paired = TRUE)
m2t2 <- t.test(d7$Symmetric.5, d7$Moderate.5, paired = TRUE)
m2t3 <- t.test(d7$Symmetric.5, d7$Strong.5, paired = TRUE)
m2t1
m2t2
m2t3
rm(d6, d7)
View(d1)
## follow-up t-tests
d8 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew', 'magval'))
View(d8)
d8$skew_magval <- interaction(d8$deg_skew, d8$magval)
d9 <- spread(d8[,c(1,9,5)], 'skew_magval', 'accept')
## follow-up t-tests
d8 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew', 'magval'))
d8$skew_magval <- interaction(d8$deg_skew, d8$magval)
d9 <- spread(d8[,c(1,9,5)], 'skew_magval', 'accept')
View(d9)
View(d8)
m3t1 <- t.test(d9$Symmetric.loss.5, d9$Weak.loss.5, paired = TRUE)
m3t1
m3t2 <- t.test(d9$Symmetric.loss.5, d9$Moderate.loss.5, paired = TRUE)
m3t2
m3t3 <- t.test(d9$Symmetric.loss.5, d9$Strong.loss.5, paired = TRUE)
m3t3
m3t4 <- t.test(d9$Symmetric.gain.5, d9$Moderate.gain.5, paired = TRUE))
m3t4 <- t.test(d9$Symmetric.gain.5, d9$Moderate.gain.5, paired = TRUE)
m3t4
b1t4 <- t.test(d3$Moderate, d3$Strong, paired = TRUE)
##follow-up t-tests
d2 <- summarySE(d1, 'accept', groupvars = c('ID', 'deg_skew'))
d3 <- spread(d2[,c(1,2,4)], 'deg_skew', 'accept')
b1t1 <- t.test(d3$Symmetric, d3$Weak, paired = TRUE)
b1t2 <- t.test(d3$Symmetric, d3$Moderate, paired = TRUE)
b1t3 <- t.test(d3$Symmetric, d3$Strong, paired = TRUE)
b1t4 <- t.test(d3$Moderate, d3$Strong, paired = TRUE)
b1t4
b1t1 <- t.test(d3$Symmetric, d3$Weak, paired = TRUE)
b1t2 <- t.test(d3$Weak, d3$Moderate, paired = TRUE)
b1t3 <- t.test(d3$Moderate, d3$Strong, paired = TRUE)
b1t4 <- t.test(d3$Moderate, d3$Strong, paired = TRUE)
b1t1
b1t2
b1t3
m1t1 <- t.test(d5$Symmetric.loss, d5$Weak.loss, paired = TRUE)
m1t1
m1t2 <- t.test(d5$Symmetric.loss, d5$Moderate.loss, paired = TRUE)
m1t2
m1t1 <- t.test(d5$Symmetric.loss, d5$Weak.loss, paired = TRUE)
m1t2 <- t.test(d5$Weak.loss, d5$Moderate.loss, paired = TRUE)
m1t3 <- t.test(d5$Moderate.loss, d5$Strong.loss, paired = TRUE)
m1t1
m1t2
m1t3
